{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQQoQowmaglguLQsJjp53+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpcompartir/dl_notebooks/blob/main/hf_sent_alg_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAOBvBYfSjpr"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.19.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "skeleton notebook for running sent alg."
      ],
      "metadata": {
        "id": "FFDniEocTFlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline \n",
        "from google.colab import files \n",
        "import numpy as np \n",
        "import torch\n",
        "\n",
        "import io\n",
        "from io import BytesIO "
      ],
      "metadata": {
        "id": "CvzGllOqSkjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = files.upload()"
      ],
      "metadata": {
        "id": "rvXuOXoFSm73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def share_sent(df, auth_token = \"censored\", model_checkpoint = \"jpcompartir/share_sent_es\", batch_size = 64, text_variable = \"text\"):\n",
        "  \n",
        "  device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "  texts = df[text_variable].tolist()\n",
        "  original_id = df[\"original_id\"].tolist()\n",
        "\n",
        "  auth_token = auth_token\n",
        "  model_checkpoint = model_checkpoint\n",
        "  \n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_auth_token = auth_token, model_max_length = 128, truncation = True)\n",
        "\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, use_auth_token = auth_token)\n",
        "  model.to(device)\n",
        "\n",
        "  pipe = TextClassificationPipeline(model = model, tokenizer = tokenizer, return_all_scores = True, device = 0, truncation = True, batch_size = batch_size)\n",
        "\n",
        "  results = pipe(texts)\n",
        "  results_df = pd.DataFrame.from_dict(results).apply(lambda x: pd.Series([dict[\"score\"] for dict in x])).rename(columns = {0: \"positive\", 1:\"negative\", 2: \"neutral\"})\n",
        "  results_df[\"py_document\"] = np.arange(1, len(results) + 1, 1)\n",
        "  results_df[\"text\"] = texts\n",
        "  results_df[\"original_id\"] = original_id\n",
        "\n",
        "  \n",
        "  return results_df[[\"original_id\", \"py_document\", \"text\", \"positive\", \"negative\", \"neutral\"]]"
      ],
      "metadata": {
        "id": "THrIPsuASoTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_one = share_sent(df)"
      ],
      "metadata": {
        "id": "HSOzvHETSzuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_one.head()"
      ],
      "metadata": {
        "id": "_SAJ4JH2S44c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_one_csv = results_one.to_csv(\"results_one.csv\", index = False)"
      ],
      "metadata": {
        "id": "q1cllLLIS6bJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(\"results_one.csv\")"
      ],
      "metadata": {
        "id": "TGk39CZrS7-o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}